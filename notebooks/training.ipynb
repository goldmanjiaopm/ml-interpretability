{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = str(Path.cwd().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from src.training_pipeline.train import train_and_evaluate, load_processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tfidf_aaa  tfidf_aarp  tfidf_abbott  tfidf_abele  tfidf_ability  \\\n",
      "0        0.0         0.0           0.0          0.0            0.0   \n",
      "1        0.0         0.0           0.0          0.0            0.0   \n",
      "2        0.0         0.0           0.0          0.0            0.0   \n",
      "3        0.0         0.0           0.0          0.0            0.0   \n",
      "4        0.0         0.0           0.0          0.0            0.0   \n",
      "\n",
      "   tfidf_able  tfidf_abolish  tfidf_abolishing  tfidf_abortion  \\\n",
      "0         0.0            0.0               0.0             0.0   \n",
      "1         0.0            0.0               0.0             0.0   \n",
      "2         0.0            0.0               0.0             0.0   \n",
      "3         0.0            0.0               0.0             0.0   \n",
      "4         0.0            0.0               0.0             0.0   \n",
      "\n",
      "   tfidf_abortions  ...  unions  urban  veterans  voting-record  water  \\\n",
      "0              0.0  ...       0      0         0              0      0   \n",
      "1              0.0  ...       0      0         0              0      0   \n",
      "2              0.0  ...       0      0         0              0      0   \n",
      "3              0.0  ...       0      0         0              0      0   \n",
      "4              0.0  ...       0      0         0              0      0   \n",
      "\n",
      "   wealth  weather  welfare  women  workers  \n",
      "0       0        0        0      0        0  \n",
      "1       0        0        0      0        0  \n",
      "2       0        0        0      0        0  \n",
      "3       0        0        0      0        0  \n",
      "4       0        0        0      0        0  \n",
      "\n",
      "[5 rows x 5142 columns]\n",
      "0    2\n",
      "1    2\n",
      "2    1\n",
      "3    0\n",
      "4    4\n",
      "Name: Labels, dtype: int64\n",
      "Training data shape: (8192, 5142)\n",
      "Training data labels: (8192,)\n",
      "Validation data shape: (2048, 5142)\n",
      "Validation data labels: (2048,)\n"
     ]
    }
   ],
   "source": [
    "# Load the processed data\n",
    "train_features, train_labels, val_features, val_labels = load_processed_data()\n",
    "\n",
    "print(train_features.head())\n",
    "print(train_labels.head())\n",
    "\n",
    "print(\"Training data shape:\", train_features.shape)\n",
    "print(\"Training data labels:\", train_labels.shape)\n",
    "print(\"Validation data shape:\", val_features.shape)\n",
    "print(\"Validation data labels:\", val_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to dict.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric, value \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to dict.__format__"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "\n",
    "config_path = Path(project_root) / \"src/training_pipeline/configs/model_configs.yaml\"\n",
    "\n",
    "metrics = train_and_evaluate(\"random_forest\", config_path)\n",
    "\n",
    "# Display metrics\n",
    "print(\"Model Metrics:\")\n",
    "\n",
    "for label, label_scores in metrics.items():\n",
    "    if isinstance(label_scores, dict):\n",
    "        print(f\"{label}:\")\n",
    "        for metric, value in label_scores.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{label}: {label_scores:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, label_scores \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(label_scores, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
